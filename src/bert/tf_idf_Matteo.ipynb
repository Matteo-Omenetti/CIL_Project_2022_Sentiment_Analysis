{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf_idf_Matteo.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPMrrvtijwaLI/jW4b3x+bB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"UfprFglXdnNk"}},{"cell_type":"code","source":["import numpy as np\n","import sklearn\n","import gensim\n","import matplotlib.pyplot as plt"],"metadata":{"id":"0Pf2ezJ0ZoWf","executionInfo":{"status":"ok","timestamp":1651494050178,"user_tz":-120,"elapsed":4,"user":{"displayName":"Matteo Omenetti","userId":"02799931472704688143"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yr0C3Q-9Zkdk","executionInfo":{"status":"ok","timestamp":1651494066619,"user_tz":-120,"elapsed":16170,"user":{"displayName":"Matteo Omenetti","userId":"02799931472704688143"}},"outputId":"1b463203-becd-4218-c0a4-8dd3158925b0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# constants and global variables\n","DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/CIL/Dataset/{}'\n","MODEL_PATH = '/content/drive/MyDrive/Colab Notebooks/CIL/Models/{}'\n","\n","# if set to true the trainig of the classifier models will be performed, otherwise the \n","# models will be loaded from a file (if present)\n","is_train_enabled = True"],"metadata":{"id":"yp3uZOIHZrog","executionInfo":{"status":"ok","timestamp":1651494066620,"user_tz":-120,"elapsed":6,"user":{"displayName":"Matteo Omenetti","userId":"02799931472704688143"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Read Preprocessed Data"],"metadata":{"id":"UFGe452DZ13u"}},{"cell_type":"code","source":["def load_X_data(file_name):\n","  tweets = []\n","  with open(DATA_PATH.format(file_name), 'r', encoding='utf-8') as f:\n","      for line in f:\n","        tweets.append(line.rstrip().split())\n","  \n","  return np.array(tweets)\n","\n","X_train = load_X_data(\"X_train_processed.txt\")\n","X_test = load_X_data(\"X_test_processed.txt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PCv_q-NNZ5o1","executionInfo":{"status":"ok","timestamp":1651494075230,"user_tz":-120,"elapsed":8614,"user":{"displayName":"Matteo Omenetti","userId":"02799931472704688143"}},"outputId":"445ea44f-d019-4c3d-87e7-263f2452e262"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  import sys\n"]}]},{"cell_type":"code","source":["def load_y_data(file_name):\n","  labels = []\n","  with open(DATA_PATH.format(file_name), 'r', encoding='utf-8') as f:\n","      for line in f:\n","        labels.append(int(line.rstrip()))\n","  \n","  return np.array(labels)\n","\n","y_train = load_y_data(\"y_train.txt\")"],"metadata":{"id":"1KBvk8kYZ-yj","executionInfo":{"status":"ok","timestamp":1651494076898,"user_tz":-120,"elapsed":1672,"user":{"displayName":"Matteo Omenetti","userId":"02799931472704688143"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["for i in range(10):\n","  print(X_train[i])\n","  print(X_test[i])\n","  print(y_train[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iYkorfbNbvtt","executionInfo":{"status":"ok","timestamp":1651494076898,"user_tz":-120,"elapsed":6,"user":{"displayName":"Matteo Omenetti","userId":"02799931472704688143"}},"outputId":"523fe1e3-e5d1-41b1-cc48-a584602e5133"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["['yes', 'even', 'realize', 'really', 'wanted', 'respond', 'want', 'buy', 'candy', 'something']\n","['sea', 'doo', 'pro', 'sea', 'scooter', 'sport', 'portable', 'sea', 'doo', 'seascootersave', 'air']\n","1\n","['bradly', 'james', 'lowrey', 'bestfriend', 'mean', 'alot', 'justthoughtidleteveryoneknow']\n","['shuck', 'well', 'work', 'week', 'come', 'cheer', 'oh', 'put', 'battery', 'calculator']\n","1\n","['mckleinusa', 'ashburn', 'series', 'leather', 'laptop', 'case', 'brown', 'clean', 'front', 'flap', 'design', 'secure', 'key', 'l']\n","['cant', 'stay', 'away', 'bug', 'thats', 'baby']\n","0\n","['next', 'time', 'ima', 'come', 'yo', 'class', 'nd', 'wake', 'wanted', 'come', 'get', 'hug', 'sleep']\n","['lol', 'im', 'perfectly', 'fine', 'contagious', 'anymore', 'lmao']\n","0\n","['trivial', 'pursuit', 'junior', 'second', 'edition', 'second', 'edition', 'junior', 'legendary', 'trivial', 'pursuit', 'game']\n","['whenever', 'fall', 'asleep', 'watching', 'tv']\n","0\n","['new', 'bbm', 'add', 'please', 'pin']\n","['need', 'get', 'rid', 'thing', 'scare', 'lol', 'need', 'car', 'either', 'need', 'driver', 'ed']\n","1\n","['morning', 'still', 'baby', 'everything', 'calmed', 'last', 'night', 'thanks', 'message', 'though']\n","['whatever', 'terrible', 'mood']\n","1\n","['custom', 'picture', 'frame', 'poster', 'frame', 'wide', 'complete', 'smooth', 'cherry', 'frame', 'frame', 'man']\n","['yes', 'rt', 'thanks', 'jordan']\n","0\n","['yeah', 'made', 'cry', 'like', 'little', 'bitch', 'love', 'luke']\n","['friend', 'text', 'check', 'last', 'night']\n","0\n","['london', 'fgs', 'please', 'come', 'north']\n","['followback', 'please', 'ur', 'unitytour', 'come', 'europe', 'sweden']\n","0\n"]}]},{"cell_type":"markdown","metadata":{"id":"qn4wCyoSK0lB"},"source":["# TF-IDF"]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# join each tweet back into a single string\n","X_train = list(map(lambda tweet : \" \".join(tweet), X_train))\n","X_test = list(map(lambda tweet : \" \".join(tweet), X_test))\n","\n","# this function is to prevent the TfidfVectorizer to perfrom its own preprocessing\n","def dummy_fun(doc):\n","    return doc\n","\n","# define the model\n","tfidf = TfidfVectorizer(\n","    analyzer='word',\n","    tokenizer=dummy_fun,\n","    preprocessor=dummy_fun,\n","    token_pattern=None,\n","    ngram_range=(1,2),\n","    max_df=0.5,\n","    min_df=100)\n","\n","# Fit the tfidf model\n","tfidf.fit(X_train)\n","\n","feature_names = tfidf.get_feature_names_out()\n","print(\"Number of features: {}\".format(len(tfidf.idf_)))\n","\n","X_train = tfidf.transform(X_train)\n","X_test = tfidf.transform(X_test)\n","\n","print(\"X_train shape is {}\".format(X_train.shape))\n","print(\"X_test shape is {}\".format(X_test.shape))"],"metadata":{"id":"YWZLpCcnMe-t","executionInfo":{"status":"ok","timestamp":1651494329217,"user_tz":-120,"elapsed":252322,"user":{"displayName":"Matteo Omenetti","userId":"02799931472704688143"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3b841622-0675-44e7-8d24-69a090d2cee2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of features: 1153\n","X_train shape is (2500000, 1153)\n","X_test shape is (10000, 1153)\n"]}]},{"cell_type":"markdown","source":["## Models\n","Apply standard machine learning models to the words embeddings that come out of TF-IDF."],"metadata":{"id":"657FErZtQEnP"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# split the model into training test and validation\n","X_train, X_test_tmp, y_train, y_test_tmp = train_test_split(X_train, y_train, test_size=0.20, random_state=33)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.12, random_state=33)"],"metadata":{"id":"ELWrNL6LdEFI","executionInfo":{"status":"ok","timestamp":1651494331688,"user_tz":-120,"elapsed":2477,"user":{"displayName":"Matteo Omenetti","userId":"02799931472704688143"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### SVM"],"metadata":{"id":"ewEvDuJeQmL8"}},{"cell_type":"code","source":["from sklearn.svm import LinearSVC\n","# define model\n","model = LinearSVC(penalty='l1', dual=False, class_weight='balanced', fit_intercept=True,\n","                random_state=65, tol=1e-5)"],"metadata":{"id":"x5QstnMsP6FA","executionInfo":{"status":"ok","timestamp":1651494331689,"user_tz":-120,"elapsed":5,"user":{"displayName":"Matteo Omenetti","userId":"02799931472704688143"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from joblib import dump, load\n","\n","# train model\n","if is_train_enabled:\n","  model.fit(X_train, y_train)\n","  dump(model, MODEL_PATH.format('svc_tf_idf.joblib')) "],"metadata":{"id":"C-TqOg_7QtlW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651495360082,"user_tz":-120,"elapsed":1028396,"user":{"displayName":"Matteo Omenetti","userId":"02799931472704688143"}},"outputId":"4ed9fd5f-a846-4168-bddf-fff736dfcf54"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]}]},{"cell_type":"code","source":["# load the trained model from file\n","model = load(MODEL_PATH.format('svc_tf_idf.joblib')) "],"metadata":{"id":"9jT2Qj0KRIlm","executionInfo":{"status":"aborted","timestamp":1651494037280,"user_tz":-120,"elapsed":13,"user":{"displayName":"Matteo Omenetti","userId":"02799931472704688143"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import f1_score, accuracy_score\n","\n","# Plot scores\n","y_pred = model.predict(X_test_tmp)\n","\n","f1 = f1_score(y_test_tmp, y_pred, average=\"macro\")\n","print(\"Test f1 score : %s \"% f1)\n","\n","acc = accuracy_score(y_test_tmp, y_pred)\n","print(\"Test accuracy score : %s \"% acc)"],"metadata":{"id":"QKZO8wT-RS9u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651495360478,"user_tz":-120,"elapsed":404,"user":{"displayName":"Matteo Omenetti","userId":"02799931472704688143"}},"outputId":"196ffdce-541d-4af1-cd75-595bad5e1bcf"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Test f1 score : 0.7095736635171892 \n","Test accuracy score : 0.709598 \n"]}]},{"cell_type":"code","source":["# Function to plot feature importance\n","def plot_feature_importance(feature_imp, feature_name, N=30):\n","  \n","  indices = np.flip(np.argsort(np.absolute(feature_imp)))\n","\n","  plt.figure()\n","  plt.rcParams['figure.figsize'] = [10, 6]\n","  plt.title(\"Feature importances: {}\".format(feature_name))\n","  plt.bar(range(N), np.absolute(feature_imp[indices[:N]]),\n","          color=\"r\", align=\"center\")\n","  plt.xticks(range(N), feature_names[indices], rotation=90)\n","  plt.xlim([-1, N])\n","  plt.show()\n","\n","  print('\\n')\n","\n","\n","for i, c in enumerate(model.coef_):\n","    plot_feature_importance(c, i)"],"metadata":{"id":"m6hg_Y24RalU","executionInfo":{"status":"aborted","timestamp":1651494037281,"user_tz":-120,"elapsed":14,"user":{"displayName":"Matteo Omenetti","userId":"02799931472704688143"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_importances(feature_imp, label):\n","  \n","  features = np.flip(np.sort(np.absolute(feature_imp)))\n","  plt.figure(figsize = (10,6))\n","  plt.scatter(x = range(features.shape[0]), y = features)\n","  plt.xlim(left = 0)\n","  plt.ylabel(\"Feature importance\", size = 16)\n","  plt.title(\"Feature importance: {}\".format(label), size = 20)\n","  plt.show()\n","  print('\\n')\n","\n","for i, c in enumerate(model.coef_):\n","    plot_importances(c, i)"],"metadata":{"id":"3DSHWsRTRmVa","executionInfo":{"status":"aborted","timestamp":1651494037281,"user_tz":-120,"elapsed":13,"user":{"displayName":"Matteo Omenetti","userId":"02799931472704688143"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n","\n","# Plot confusion matrix\n","cm = confusion_matrix(y_test_tmp, y_pred)\n","\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2,3])\n","\n","disp.plot(cmap=plt.cm.Blues)\n","plt.show()"],"metadata":{"id":"Bl6Ft2jMSGbT","executionInfo":{"status":"aborted","timestamp":1651494037281,"user_tz":-120,"elapsed":13,"user":{"displayName":"Matteo Omenetti","userId":"02799931472704688143"}}},"execution_count":null,"outputs":[]}]}